%\documentclass{beamer}
\documentclass[handout]{beamer}
%\usepackage{beamerthemesplit} // Activate for custom appearance
\usetheme{Boadilla}
\newtheorem{Proposition}[theorem]{Proposition}%
\newcommand{\BP}{\mathbf{P}}
\newcommand{\BE}{\mathbf{E}}
\newcommand{\BI}{\mathbf{1}}
\newcommand{\BV}{\mathbf{Var}}



\setbeamertemplate{theorems}[numbered]

\title{STAT 7200}
 \subtitle{Introduction to Advanced Probability \newline Lecture 19}
\author{Taylor R. Brown}
\institute{}
\date{}

\begin{document}

\frame{\titlepage}


\section[Outline]{}
\frame{\tableofcontents}


\subsection{Weak Convergence}



\frame
{
  \frametitle{Equivalent Definitions of Weakly Convergence} 

   \begin{itemize}

               \item<1->[] \begin{Theorem}[Equivalent Definitions of Weakly Convergence] The following statements are all equivalent definition of weak convergence:

               (1) $\{\mu_n\}$ converges weakly to $\mu$. (Original definition) 
               \vspace{2mm}
               
                 {\color{blue} (2) $\mu_n(A)\rightarrow \mu(A)$ for all measurable set $A$ such that $\mu(\partial A)=0$. ($\partial A$ is defined as the boundary of set $A$) }
                              \vspace{2mm}

               (3) $\mu_n((-\infty, x])\rightarrow \mu((-\infty, x])$ for all $x\in \mathbf{R}$ such that $\mu(\{x\})=0$. That is, the convergence of CDFs. (Note, $\{x\}$ is the boundary of set $(-\infty, x]$.)
                              \vspace{2mm}

                 {\color{blue}  (4) (Skorohod's Theorem) there are random variable $Y, Y_1, Y_2, \cdots$ defined on the same probability triple, with $\mathcal{L} (Y)=\mu$ and $\mathcal{L} (Y_n)=\mu_n $ such that $Y_n\rightarrow Y$ with probability 1 (This theorem connects the strongest type of convergence: convergence almost surely, with the week convergence.) }
                              \vspace{2mm}

               (5) $\int_{\mathbf{R}}f d\mu_n \rightarrow \int_{\mathbf{R}}f d\mu$ for all bounded Borel-measurable functions $f:\mathbf{R}\rightarrow \mathbf{R}$. such that $\mu(D_f)=0$, where $D_f$ is the set of discontinuous points of $f$. (The continuous condition of definition 1) is relaxed.)
              
                            \end{Theorem}

                                               \end{itemize}
}



\frame
{
  \frametitle{Structure of Proof} 

   \begin{itemize}

               \item<1-> Our proof will follow the following structure: 
%                    \begin{figure}[c]
%                       \includegraphics[scale=0.3]{StructureofProof.pdf}
% \end{figure}   
                     
                    \item<2-> We have proved:   $(5)\Rightarrow (1)$,  $(5)\Rightarrow (2)$ and  $(2)\Rightarrow (3)$
                                       
                     
                     
                                               \end{itemize}
}




\frame
{
  \frametitle{Proof: $(1) \Rightarrow (3)$ } 

   \begin{itemize}

\item<1->
               
                (1)  $\{\mu_n\}$ converges weakly to $\mu$:  $\int_{\mathbf{R}} f d\mu_n \rightarrow \int_{\mathbf{R}}f d\mu$ for all bounded continuous functions $f$.
                              \vspace{2mm}


               {\color{blue}  (3) $\mu_n((-\infty, x])\rightarrow \mu((-\infty, x])$ for all $x\in \mathbf{R}$ such that $\mu(\{x\})=0$.}
                                            \vspace{2mm}

               
               
               
                     \item<2-> \textbf{Strategy:}  We can not apply $(1)$ directly by setting $f=\BI_{(-\infty, x]}$ since $\BI_{(-\infty, x]}$, although bounded, is discontinuous at $x$. We may resolve this issue by  constructing continuous approximation  of $\BI_{(-\infty, x]}$. 
                     
                     \item<3-> \textbf{Proof:} For any $\varepsilon>0$ (which is used to control how good the approximation is), define $f(t)=1$ for $t\leq x$ and $0$ for $t\geq x+\varepsilon$, but let $f(t)$ be a linear function on $(x, x+\varepsilon)$. 
                     \item<4->[-]  As $f$ is now continuous and $\BI_{(-\infty, x]} \leq f \leq \BI_{(-\infty, x+\varepsilon]}$:
                     $$\limsup_n \mu_n((-\infty, x]) \leq \limsup_n \int f d\mu_n=\int f d\mu \leq \mu((-\infty, x+\varepsilon])$$
                     
                     \item<5->[-] Let $\varepsilon\rightarrow 0$. By the continuity of probability, we have $\limsup_n \mu_n((-\infty, x]) \leq \mu((-\infty, x])$
                     
                                         
                                               \end{itemize}
}


\frame
{
  \frametitle{Proof: $(1) \Rightarrow (3)$: continued} 

   \begin{itemize}

                     \item<1-> \textbf{Proof: continued} Similarly, define $f(t)=1$ for $t\leq x-\varepsilon$ and $0$ for $t\geq x$, but let $f(t)$ be a linear function on $(x-\varepsilon, x)$. Then $f$ is linear and $\BI_{(-\infty, x-\varepsilon]} \leq f \leq \BI_{(-\infty, x]}$. And:
                     $$\liminf_n \mu_n((-\infty, x]) \geq \liminf_n \int f d\mu_n=\int f d\mu \geq \mu((-\infty, x-\varepsilon])$$
                     
              \item<2->[-]     Let $\varepsilon\rightarrow 0$, $\liminf_n \mu_n((-\infty, x]) \geq \mu((-\infty, x) )=\mu((-\infty, x])$. The last equality holds since $\mu(\{x\})=0$. 
              
              \item<3->[-]  In summary:  $$\liminf_n \mu_n((-\infty, x]) \geq \mu((-\infty, x]) \geq \limsup_n \mu_n((-\infty, x])$$
               
               \item<4->[-] we then must have:  $$\lim_n \mu_n((-\infty, x]) =\mu((-\infty, x]) $$                    
                                               \end{itemize}
}


\frame
{
  \frametitle{Proof: $(4) \Rightarrow (5)$ } 

   \begin{itemize}

\item<1->
               


               (4) there are random variable $Y, Y_1, Y_2, \cdots$ defined on the same probability triple, with $\mathcal{L} (Y)=\mu$ and $\mathcal{L} (Y_n)=\mu_n $ such that $Y_n\rightarrow Y$ with probability 1.
                                                           \vspace{2mm}
                                                           
                                                           

            {\color{blue}   (5) $\int_{\mathbf{R}}f d\mu_n \rightarrow \int_{\mathbf{R}}f d\mu$ for all bounded Borel-measurable functions $f:\mathbf{R}\rightarrow \mathbf{R}$. such that $\mu(D_f)=0$, where $D_f$ is the set of discontinuous points of $f$. }
              
                                            \vspace{2mm}

               
\item<2-> \textbf{Proof:} Pick an appropriate $f$. First, we want to show that $P\left( f(Y_n) \to f(Y) \right) = 1$. Note that
\begin{itemize}
\item $0 \le P(Y_n(\omega) \to Y(\omega), D_f) \le P( D_f) = 0$
\item$1 = P(Y_n \to Y) = P(Y_n \to Y, D_f) + P(Y_n \to Y, D_f^c) =  P(Y_n \to Y, D_f^c)$
\item $\{\omega : f(Y_n) \to f(Y)\} \supseteq \{\omega :  Y_n(\omega) \to Y(\omega)\} \cap \{\omega :  Y(\omega) \in D_f^c \}$
\end{itemize}
so $f(Y_n) \to f(Y)$ wp1 by (4) and monotonicity of $\BP$.

\item<3->[-] Because $f$ is bounded, $f(Y)$ is integrable, so $\BE[f(Y_n)]\rightarrow \BE[f(Y)]$ by the dominated convergence theorem.

\end{itemize}
}



\frame
{
  \frametitle{Proof: $(3) \Rightarrow (4)$ } 

   \begin{itemize}

\item<1-> (3) $\mu_n((-\infty, x])\rightarrow \mu((-\infty, x])$ for all $x\in \mathbf{R}$ such that $\mu(\{x\})=0$.
                                            \vspace{2mm}

              {\color{blue}  (4) there are random variables $Y, Y_1, Y_2, \ldots$ defined on the same probability triple, with $\mathcal{L} (Y)=\mu$ and $\mathcal{L} (Y_n)=\mu_n $ such that $Y_n\rightarrow Y$ with probability 1 }
                                                           \vspace{2mm}

               
\item<2-> \textbf{Strategy:}  We will construct random variables with CDFs $F_n(x)=\mu_n((-\infty, x])$, $F(x)=\mu((-\infty, x])$, then we will show the convergence of these random variables using the fact that the corresponding CDFs converge.
                     
\end{itemize}
}

\frame
{
  \frametitle{Proof: $(3) \Rightarrow (4)$:  Probability Integral Transform} 

We can construct random variable with given CDF using \textbf{probability integral transform}, which transforms a random variable using the quantile function. \\

Define the \textbf{quantile function} as

$$
Q(p)=\inf \{x: F(x) \geq p\}
$$

Useful facts:

\begin{itemize}

\item<1->[-] $F(q)\geq p \iff Q(p)\leq q $
                
                                          
\item<2->[-] $F(q)< p \Rightarrow Q(p)\ge q$

                       
\item<3->[-]When the CDF is continuous and strictly increasing, the quantile function is the inverse of CDF.  
                       
                       
\item<4->[-] The quantile function $Q(p)$ is a non-decreasing function, same as the CDF.

\end{itemize}

}









        




\frame
{
  \frametitle{Proof: $(3) \Rightarrow (4)$:  Probability Integral Transform} 

The \textbf{probability integral transform}:

\begin{itemize}

\item<1->[-] Let $U \sim \text{Uniform}(0,1)$. Then the random variable $Q(U)$ follows a distribution with CDF $F$. 


\item<2->[-] \textbf{Proof:} $$\BP[Q(U)\leq x] =\BP [F(x) \geq U]=F(x)$$

\end{itemize}


}





\frame
{
  \frametitle{Proof: $(3) \Rightarrow (4)$: continued} 


\begin{enumerate}
                   
\item Another fact we'll need, any nondecreasing function $f$ has at most a countable number of discontinuities. 

\item Call the set of discontinuities $D_f$. Suppose for starters that $f : [a,b] \to \mathbb{R}$ (e.g. a quantile function).  $D_f = \bigcup_{n} \{  \frac{1}{n} \le  f(x^+) - f(x^-) \}$.

\item $|\{  \frac{1}{n} \le  f(x^+) - f(x^-) \}| \le n [f(b) - f(a)]$

\item Countable unions of finite sets are countable!


\end{enumerate}
}


\frame
{
  \frametitle{Proof: $(3) \Rightarrow (4)$: continued} 


\begin{enumerate}
                   
\item Remove the assumption of compact domain (e.g. a cdf).

\item Call the set of discontinuities $D_f$ again.  For any integer $z$, let $D_{zf}$ be the set of discontinuities on $[z,z+1]$. 

\item Clearly $D_f = \bigcup_{z \in \mathbb{Z}} D_{zf}$.

\item Countable unions of countable sets are countable!

\end{enumerate}
}



\frame
{
  \frametitle{Proof: $(3) \Rightarrow (4)$: continued} 

\begin{itemize}
          
                     
\item<1-> \textbf{Proof: continued} Let $F_n(x)=\mu_n((-\infty, x])$, $F(x)=\mu((-\infty, x])$, and let $(\Omega, \mathcal{F}, \lambda)$ be a probability triple with the uniform measure over $\Omega=[0,1]$, and $Y_n(\omega)=\inf \{y: F_n(y) \geq \omega\}$, $Y(\omega)=\inf \{y: F(y) \geq \omega\}$. Then $Y_n$ has CDF $F_n(x)$ and $Y$ has CDF $F(x)$.  
                     
                     
    \item<2->[-] Now we will show that $\{\omega : Y \text{ is continuous at } \omega\} \subseteq  \{ \omega : Y_n(\omega) \rightarrow Y(\omega)\}$ 
                     
\item<3->[-] Roadmap: assume cty of $Y$, get inequality for $F$, get inequality for $F_n$, get inequality for $Y_n$. 

                                         
\end{itemize}
}





\frame
{
  \frametitle{Proof: $(3) \Rightarrow (4)$: continued} 

\begin{itemize}
          
\item<1-> \textbf{Proof: continued} Define $Y(\omega) = y$. Then $y-\varepsilon<y< y+\varepsilon$ implies:
                                                  $$F(y-\varepsilon)< \omega < F(y+\varepsilon) $$
                         
if $Y(\omega)$ is continuous at $\omega$. Why?
                         
                %   \item<4->[-] The reason is, if  $F(y-\varepsilon)=\omega$, then $Y(\omega ) \leq y-\varepsilon$, but $Y(\omega)=y$, then $y\leq y-\varepsilon$, a contradiction. 
                   
\item<2-> The weak inequalities are obviously true. if $F(y+\varepsilon)=\omega$, then for any $\delta>0$, $F(y+\varepsilon)<\omega+\delta$, then $Y(\omega+\delta) \ge y+\varepsilon=Y(\omega)+\varepsilon$. This indicates that there is a jump of at least size $\varepsilon$ of $Y(\omega)$ at $\omega$, which is a contradiction to the continuity of $Y$ at $\omega$. 
                   
\item<3-> The other inequality is easier. It's just the contrapositive of $F(q)\geq p \Rightarrow Q(p)\leq q $.

                                         
\end{itemize}
}




\frame
{
  \frametitle{Proof: $(3) \Rightarrow (4)$: continued} 

\begin{itemize}
          
                     
\item<1-> \textbf{Proof: continued}  In the previous slide, if $Y$ is continuous at $\omega$, and $Y(\omega)=y$, then $F(y-\varepsilon)<\omega< F(y+\varepsilon) $ for all $\varepsilon>0$. 
                     
\item<2-> Now, in addition to looking at $F$, we'll look at the $F_n$s. These converge to $F$, but only at $F$'s continuity points.


\item<3-> For a particular $\varepsilon$, we can always find $0<\varepsilon'<\varepsilon$, such that $\mu(y-\varepsilon')=\mu(y+\varepsilon')=0$. ($\mu(x)>0$ only for at most countably many $x$). Then $F_n(y-\varepsilon')\rightarrow F(y-\varepsilon')$ and $F_n(y+\varepsilon')\rightarrow F(y+\varepsilon')$. Thus, for large enough $n$, we have:  
                     $$F_n(y-\varepsilon')<\omega< F_n(y+\varepsilon') $$                  
                     
\item<4-> Since $\omega< F_n(y+\varepsilon')$, $\omega \le F_n(y+\varepsilon')$, then: 
                     
       \hspace{3cm}             $Y_n(\omega)\leq  y+\varepsilon'=Y(\omega)+\varepsilon'$. 
       
       \vspace{5mm}

\item<5-> Since $F_n(y-\varepsilon')<\omega$, then : 
                     
       \hspace{3cm}             $Y_n(\omega)\geq y-\varepsilon'=Y(\omega)-\varepsilon'$. 
                            \vspace{5mm}

\item<6-> So $|Y_n(\omega)-Y(\omega)|\leq \varepsilon'<\varepsilon$ for large enough $n$ when $Y$ is cts at $\omega$
                                                                  
\end{itemize}
}





\frame
{
  \frametitle{Proof: $(3) \Rightarrow (4)$: continued} 


\begin{enumerate}

\item \textbf{Proof: continued} We showed $\{\omega : Y \text{ is continuous at } \omega\} \subseteq  \{ \omega : Y_n(\omega) \rightarrow Y(\omega)\}$.

\item By monotonicity $\lambda(Y \text{ is continuous at } \omega ) \le  \lambda( Y_n(\omega) \rightarrow Y(\omega) )$.

\item We need to establish the fact that $Y$ is continuous with probability $1$. Or equivalently, $D_Y$, the set of the discontinuous points of $Y$, has $\lambda$-probability 0. 


\item We showed discontinuities of $Y(\omega)$, call it $D_Y$, is at most a countable. So $\lambda(D_y) = 0$.

\end{enumerate}
}



\end{document}
